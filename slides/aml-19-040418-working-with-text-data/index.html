<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Garamond);
      @import url(https://fonts.googleapis.com/css?family=Muli:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);
      body {
        font-family: 'Muli';
        font-size: 140%;
      }
      h1, h2 {
        font-family: 'Garamond';
        font-weight: normal;
        margin-top: 10px;
        margin-bottom: 10px;
      }
      .remark-slide-content h1 {
        font-size: 70px;
        text-align: center;
      }
      .remark-slide-content p, .remark-slide-content li {
        font-size:30px;
        line-height: 1.4;
      }
      .remark-code {
        font-size:30px;
      }
      .remark-slide-content p {
          margin: 5px;
      }
      .remark-slide-container .spacious p,
      .remark-slide-container .spacious li{
          margin-bottom: 50px;
          margin-top: 50px;
      }
      .remark-slide-container .spacious h1{
          margin-bottom: 50px;
      }
      .remark-slide-container .some-space p,
      .remark-slide-container .some-space li,
      .remark-slide-container .some-space h1{
          margin-bottom: 30px;
      }
      .reset-column {
          overflow: auto;
          width: 100%;
      }
      .remark-slide-content .compact p, .remark-slide-content .compact li, .remark-slide-content .compact pre, .remark-slide-content .compact .MathJax_Display{
          font-size: 30px;
          line-height: 1.1;
          display: block;
          margin: 2px 0;
      }
      .padding-top {
          padding-top: 100px;
      }
      .remark-slide-content .smaller p, .remark-slide-content .smaller li,
      .remark-slide-content .smaller .remark-code, .remark-slide-content .smaller a{
          font-size: 25px;
      }
      .normal {
          font-size: 30px;
      }
      .quote_author {
          display: block;
          text-align: right;
          margin-top: 20px;
          font-size: 30px;
          font-family: 'Garamond';
      }
      .larger, .larger .remark-code {
          font-size: 40px;
      }
      .largest, .largest .remark-code {
          font-size: 50px;
      }
      .left-column, .right-column {
          width: 48%;
      }
      .right-column{
          float: right;
      }
      .left-column{
          float: left;
      }
      .narrow-right-column {
          float: right;
          width: 32%
      }
      .wide-left-column {
          float: left;
          width: 65%
      }
      .invisible {
          visibility: hidden
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

### W4995 Applied Machine Learning

# Working with Text Data

04/04/18

Andreas C. MÃ¼ller

---

# More kinds of data


- So far:
  * Fixed number of features
  * Contiguous
  * Categorical
- Next up:
  * No pre-defined features
  * Free text
  * Images
  * (Audio: not this class)
  * Need to create fixed-length description

???
---
# Typical Text Data

<br>

.center[
![:scale 100%](images/typical_text_data_1.png)
]

<br>
<br>

.center[
![:scale 100%](images/typical_text_data_2.png)
]



???
---
# Other Types of text data

.center[
![:scale 100%](images/other_types_of_text_data.png)
]

???
---

# Features from Text:  
# Bag of Words

<br>
.center[
![:scale 60%](images/bag_of_words.png)
]
???
---
# Toy Example

Consider two documents in a dataset

.center[
![:scale 70%](images/toy_example.png)
] 

???
---
# bag

<br>

.center[
![:scale 80%](images/toy_example_bag.png)
]

???
---
class: center, middle

# Text classification example: IMDB Movie Reviews

---

# Data loading
<br>

.center[
![:scale 100%](images/data_loading.png)
]

???
---
# Vectorization
<br>

.center[
![:scale 100%](images/vectorization.png)
]


---

#Once we have X, business as usual

<br>

.center[
![:scale 100%](images/vectorization_res.png)
]


???
---
class: middle

.center[
![:scale 100%](images/vectorization_plot.png)
]



---
class:spacious
# Soo many options!

- How to tokenize?
- How to normalize words?
- What to include in vocabulary?

---
# Tokenization
- Scikit-learn (very simplistic):
  * re.findall(r"\b\w\w+\b")
  * Includes numbers
  * doesn't include single-letter words
  * doesn't include - or '
- Can change regular expression "token pattern":
.center[
![:scale 60%](images/tokenization.png)
]


---

#Normalization
- Correct spelling?
- Stemming: reduce to word stem
- Lemmatization: reduce words to stem using curated dictionary and context
- scikit-learn:
  * Lower-case it
  * Configurable, use nltk or spacy



---
class: center, middle

# Restricting the Vocabulary


---

# Stop Words


![:scale 70%](images/stop_words.png)

- For supervised learning often little effect on large corpuses (on small corpuses and for unsupervised learning it can help)

---
# Infrequent Words

- Words that appear only once or twice might not be helpful:
.center[
![:scale 50%](images/infreq_words_1.png)
]

- Restrict vocabulary size to only most frequent words (for less features):

.center[
![:scale 50%](images/infreq_words_2.png)
]


---
.center[
![:scale 40%](images/infreq_words_3.png)
]

- Removed nearly 1/3 of features!

.center[
![:scale 40%](images/infreq_words_4.png)
]

- As good as before


---
# Beyond single words
- Bag of words completely removes word order.
- "didn't love" and "love" are very different!
- N-grams: tuples of consecutive words

.center[
![:scale 70%](images/single_words.png)
]


---

# Bigrams toy example

.center[
![:scale 100%](images/bigrams_toy_example.png)
]

- Typically: higher n-grams lead to blow up of feature space!

---
# N-grams on IMDB data

.center[
![:scale 100%](images/ngrams_imdb.png)
]


- More than 20x more 4-grams!

---
#Stop-word impact on bi-grams

.center[
![:scale 100%](images/stop_words_bigram.png)
]

---
# Stop-word impact on 4-grams
.center[
![:scale 100%](images/stopwords_4gram.png)
]

---
- Stopwords included
.center[
![:scale 75%](images/stopwords_1.png)
]

- stopwords removed (slightly worse)
.center[
![:scale 75%](images/stopwords_2.png)
]

---
.center[
![:scale 100%](images/stopwords_3.png)
]
---

Tf-idf rescaling

$$ tf\text{-}idf(t,d) = tf(t,d)\cdot idf(t)$$

$$ idf(t) = log\frac{1+n_d}{1+df(d,t)} + 1$$

Where, $n_d$ is the total number of documents and $df(d,t)$ is the number of documents containing term $t$

* Emplasizes "rare" words - "soft stop word removal"
* Slightly non-standard smoothing (many +1s)
* By default also L2 normalisation!

---
# TfidfVectorizer, TfidfTransformer

.center[
![:scale 100%](images/tfidf_trans.png)
]

---
class: middle

# Character n-grams

---
#Principle
<br>
<br>

.center[
![:scale 100%](images/do_you_want_ants.png)
]

---
class: spacious
#Applications

- Be robust to misspelling / obfuscation
- Language detection
- Learn from Names / made-up words

---
# Toy example

- "Naive"
.center[
![:scale 100%](images/toy_example_1.png)
]

- Respect word boundaries
.center[
![:scale 100%](images/toy_example_2.png)
]

---

# IMDB Data
.center[
![:scale 100%](images/imdb_data_params.png)
]

---
class: middle
.center[
![:scale 100%](images/imdb_data_plot.png)
]

---
class: middle

# Predicting Nationality from Name

---
.center[
![:scale 70%](images/nationality_name_1.png)
]

.center[
![:scale 70%](images/nationality_name_2.png)
]

---
# Comparing words vs chars

<br>

.center[
![:scale 100%](images/comp_word_char_1.png)
]

<br>

.center[
![:scale 100%](images/comp_word_char_2.png)
]

<br>

.center[
![:scale 100%](images/comp_word_char_3.png)
]

<br>

.center[
![:scale 100%](images/comp_word_char_4.png)
]


---

# Grid-search parameters
- Small dataset, makes grid-search faster! (less reliable)
.center[
![:scale 80%](images/grid_search_param.png)
]

---
.center[
![:scale 100%](images/grid_search_table.png)
]

---
# Other features
- Length of text
- Number of out-of-vocabularly words
- Presence / frequency of ALL CAPS
- Punctuation...!? (somewhat captures by char ngrams)
- Sentiment words (good vs bad)
- Whatever makes sense for the task!

---
class: middle

# Large Scale Text Vectorization
---

.center[
![:scale 90%](images/large_scale_text_vec_1.png)
]

---

.center[
![:scale 80%](images/large_scale_text_vec_2.png)
]

---
# Near drop-in replacement
- Careful: Uses l2 normalization by default!
.center[
![:scale 60%](images/near_drop_in_replacement.png)
]

---

# Trade-offs

.left-column[
Pro:
- Fast
- Works for streaming data
- Low memory footprint
]
.right-column[
Con:
- Can't interpret results
- Hard to debug
- (collisions are not a problem for performance)

]

---
class: middle
# Questions ?


    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script>
    // Config Remark
    remark.macros['scale'] = function (percentage) {
        var url = this;
        return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };
    config_remark = {
        highlightStyle: 'magula',
        highlightSpans: true,
        highlightLines: true,
        ratio: "16:9"
    };
      var slideshow = remark.create(config_remark);
    // Configure MathJax
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] /* removed 'code' entry*/
    }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    </script>
  </body>
</html>
